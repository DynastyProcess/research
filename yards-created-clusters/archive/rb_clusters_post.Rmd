---
title: "RB Clustering with Yards Created"
author: Joe Sydlowski
output:
  github_document:
    toc: true
    toc_depth: 3
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width=12, fig.height=8) 


#Load Libraries
library(here)
library(tidyverse)
library(arrow)
library(tidymodels)
library(skimr)
library(tidytext)
library(ggridges)
library(GGally)
library(ggthemes)

#Load ggplot themes
ggplot2::theme_set(ggthemes::theme_fivethirtyeight())

#Load Data
setwd(here::here())
yards_created_df <- read_csv("yards_created_data.csv") %>%
  mutate(name_cap = name,
         name = str_to_lower(name)) %>%
  select(name, name_cap, draft_year, draft_pick, yc_per_attempt, mtf_per_attempt, rec_yard_per_pass_play, rec_share, total_yards_per_team_play)

pbp <- read_parquet("../ep/data/fit_data/ep_1999_2019.pdata")

rb_seasons <- pbp %>%
  filter(season >= 2016, gsis_pos == "RB") %>%
  group_by(season, gsis_id, gsis_name) %>%
  summarise(rec_ypg = mean(rec_yd, na.rm = TRUE),
            rec_total = sum(rec_yd, na.rm = TRUE),
            rush_ypg = mean(rush_yd, na.rm = TRUE),
            rush_total = sum(rush_yd, na.rm = TRUE),
            ppr_ppg = mean(total_fp, na.rm = TRUE),
            ppr_total = sum(total_fp, na.rm = TRUE),
            ep_per_game = mean(total_fp_x, na.rm = TRUE),
            ep_diff_per_game = mean(total_fp_diff, na.rm = TRUE),
            ep_total_diff = sum(total_fp_diff, na.rn = TRUE),
            games = n()) %>%
  ungroup() %>%
  arrange(gsis_id, gsis_name, season) %>%
  group_by(gsis_id, gsis_name) %>%
  mutate(season_number = row_number(),
         gsis_name = str_to_lower(gsis_name)) %>%
  ungroup()

rb_seasons_wide <- rb_seasons %>%
  select(-season) %>%
  pivot_wider(names_from = season_number,
              values_from = c(rec_ypg, rec_total, rush_ypg, rush_total, ppr_ppg, ppr_total, ep_per_game, ep_diff_per_game, ep_total_diff, games),
              names_glue = "{.value}_y{season_number}") %>%
  rowwise() %>%
  mutate(ppr_ppg_total = sum(ppr_total_y1, ppr_total_y2, ppr_total_y3, ppr_total_y4, na.rm = TRUE) /
                         sum(games_y1, games_y2, games_y3, games_y4, na.rm = TRUE),
         rec_ypg_total = sum(rec_total_y1, rec_total_y2, rec_total_y3, rec_total_y4, na.rm = TRUE) /
                         sum(games_y1, games_y2, games_y3, games_y4, na.rm = TRUE),
         rush_ypg_total = sum(rush_total_y1, rush_total_y2, rush_total_y3, rush_total_y4, na.rm = TRUE) /
                         sum(games_y1, games_y2, games_y3, games_y4, na.rm = TRUE),
         ep_diff_per_game_total = sum(ep_total_diff_y1, ep_total_diff_y2, ep_total_diff_y3, ep_total_diff_y4, na.rm = TRUE) /
                         sum(games_y1, games_y2, games_y3, games_y4, na.rm = TRUE)
         ) %>%
  ungroup()

#Principal Component Analysis  
pca_rec <- recipe(~., data = yards_created_df) %>%
  update_role(name, name_cap, draft_year, new_role = "id") %>%
  step_log(draft_pick) %>%
  step_medianimpute(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 6)

pca_prep <- prep(pca_rec)

tidied_pca <- tidy(pca_prep, 4)

rb_clusters_wide <- juice(pca_prep) %>%
  pivot_longer(cols = starts_with("PC"), names_to = "Cluster") %>%
  group_by(name) %>%
  filter(value == max(value)) %>%
  ungroup() %>%
  left_join(rb_seasons_wide, by = c("name" = "gsis_name")) %>%
  left_join(yards_created_df, by = c("name", "name_cap", "draft_year"))

rb_seasons_clusters <- rb_clusters_wide %>%
  select(name, draft_year, Cluster) %>%
  left_join(rb_seasons, by = c("name" = "gsis_name")) %>%
  filter(draft_year < 2020) %>%
  mutate(season = ifelse(is.na(season),draft_year,season)) %>%
  group_by(draft_year, Cluster) %>%
  complete(name, nesting(season)) %>%
  ungroup() %>%
  arrange(name, season) %>%
  group_by(name) %>%
  mutate(season_number = row_number()) %>%
  ungroup() %>%
  mutate_if(is.numeric, ~replace(., is.na(.), 0)) %>%
  pivot_longer(cols = where(is.numeric), names_to = "Metric")

# rb_median_metrics <- rb_seasons_clusters %>%
#   pivot_wider()
#   group_by(Cluster) %>%
#   median(ppr_ppg = median(ppr_ppg)) %>%
#   ungroup()

cluster_examples <- rb_clusters_wide %>% 
  select(name_cap, draft_year, Cluster, value) %>% 
  group_by(Cluster) %>% 
  top_n(n=3, wt=value) %>%
  summarise(cluster_examples = paste(name_cap, collapse = ", ")) %>%
  ungroup()

summarydf <- rb_clusters_wide %>%
  group_by(Cluster) %>%
  summarise(across(where(is.numeric), median, na.rm = TRUE),
            player_count = n()) %>% 
  ungroup() %>%
  select(Cluster,
         player_count,
         ppr_ppg_total,
         rec_ypg_total,
         rush_ypg_total,
         ep_diff_per_game_total,
         draft_pick,
         yc_per_attempt,
         mtf_per_attempt,
         rec_yard_per_pass_play,
         rec_share,
         total_yards_per_team_play) %>% 
  arrange(desc(ppr_ppg_total)) %>% 
  left_join(cluster_examples,by = "Cluster") %>%
  mutate(across(where(is.numeric), ~round(.,3)))

```

## Introduction

Principal Component Analysis (PCA) is an unsupervised machine learning technique used to group players into clusters with similar characteristics while avoiding overfitting. I have combined this technique with some notably predictive metrics such as Graham Barfield's *Yards Created* and JJ Zachariason's *prospect model* to create tier-groupings of rookie running backs.

## Why PCA?

An unsupervised machine learning model does not have an outcome variable, which is especially useful in prospecting rookie RBs for two reasons. Many outcome variables set arbitrary thresholds where a top 24 RB season is considered a success but an RB25 finish is then considered a failure. By using an unsupervised model we can cluster similar RBs into similar groups and later see how the clusters performed in a variety of outcome variables. Secondly, using an unsupervised model prevents us from over-fitting the model on an outcome variable in our small sample sizes. For example, if you wanted to predict rushing yards for rookie RBs using draft capital a supervised machine learning model might look to undrafted free agent Phillip Lindsay's 2018 rookie season and underestimate the importance of being drafted. This over-fitting could result in high predictions for future UDFA RBs as a result.

## Exploring the Data

I used 6 variables (measured during the player's final collegiate season) from the two methodologies linked above to tier the 57 RBs with Yards Created data over the past 5 years:

* draft_pick - Overall pick number in the NFL draft
* Yards Created Variables
  + yc_per_attempt - Yards created per attempt
  + mtf_per_attempt - Missed tackles forced per attempt
  + rec_yard_per_pass_play - Receiving yards per pass play
* JJ's Prospect Model
  + rec_share - Share of team receptions
  + total_yards_per_team_play - Ratio of total yards divided by team plays

```{r correlations, echo = FALSE, message = FALSE, warning = FALSE}
yards_created_df %>%
  left_join(rb_seasons_wide, by = c("name" = "gsis_name")) %>%
  transmute(ppr_ppg_total, log(draft_pick), yc_per_attempt, mtf_per_attempt, rec_yard_per_pass_play, rec_share, total_yards_per_team_play) %>%
  ggpairs(lower = list(continuous = wrap("smooth")))

```

These 6 variables correlate to RB production per game in the first 4 years of their careers. I interpet the Yards Created variables as a proxy for RB skill as best we can measure it. This is reinforced by the fact that yards created per attempt and missed tackles forced per attempt have the two strongest correlations with draft pick. Reception share measures a team's intent to get an RB the ball in the passing game and has a strong correlation to Graham's charted receiving yards per pass play. Finally, yards per team pass attempt measures the player's efficiency in that offense. These measures of skill, volume, and efficiency create a strong foundation to create our tiers.

## Principal Component Analysis

Using the tidymodels package in R, I created 6 principal components from the 6 predictive metrics. The chart below demonstrates which of the variables contribute most strongly, either positively or negatively, to each component. Keep in mind that a smaller draft pick is actually better so the blue bars are later draft picks, while the red bars are earlier draft picks. The components PC1-PC6 are not ordered in any way and will need to be intrepreted on their own.

* First, compare and contrast PC2 to PC5 which are strongly defined by early round picks. Whereas PC2 focuses on weak receiving metrics and strong measures of efficiency and yards created, a strong receiving share is more important to PC5.
* PC1 is immediately concerning since it is mostly strongly impacted by low values in all of our predictive metrics to go along with late draft picks. Similarly PC3 consists of late draft picks and low scores for yards created and receiving yards per pass play.
* Finally, PC4 and PC6 also make for an interesting duo. Draft pick does not play an significant role in either composition, but where PC4 is defined by a strong yards created and weak missed tackles forced, PC2 is defined by a weak yards created and strong missed tackles forced.


```{r variable_importance, echo = FALSE, message = FALSE, warning = FALSE}
tidied_pca %>%
  filter(component %in% paste0("PC", 1:6)) %>%
  group_by(component) %>%
  top_n(5, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y", nrow = 3) +
  scale_y_reordered() +
  labs(
    title = "Absolute Value of Contribution",
    y = NULL,
    fill = "Positive Contribution?"
  )

```

Below you can see a snapshot of the predictive metrics and examples from each of the Principal components. The important variables from each of the components can be seen here.

```{r cluster_summary, echo = FALSE, message = FALSE, warning = FALSE, fig.width=16}
# library(kableExtra)
# summarydf %>%
#   mutate(ppr_ppg_total = cell_spec(ppr_ppg_total, background = spec_color(1:6, alpha = 0.5))) %>%
#   knitr::kable(booktabs = TRUE) %>%
#   kable_styling(c("compact","stripe","nowrap"))

library(gt)
library(RColorBrewer)

cols <- summarydf %>%
  select(is.numeric, -draft_pick) %>%
  colnames()

cols2 <- summarydf %>%
  select(is.numeric) %>%
  colnames()

gt(summarydf) %>%
  data_color(
    columns = cols,
    colors = scales::col_factor(
      #palette = 'PRGn',
      brewer.pal(12,'PRGn')[3:8],
      domain = NULL
    )) %>%
  data_color(
    columns = vars(draft_pick),
    colors = scales::col_factor(
      #palette = 'PRGn',
      brewer.pal(12,'PRGn')[8:3],
      domain = NULL
    )) %>%
  cols_label(
    Cluster = "Cluster",
    player_count = "Count",
    ppr_ppg_total = "PPR PPG",
    rec_ypg_total = "Rec YPG",
    rush_ypg_total = "Rush YPG",
    ep_diff_per_game_total = "FPOE/ Game",
    draft_pick = "Draft Pick",
    yc_per_attempt = "YC/ Att",
    mtf_per_attempt = "MTF/ Att",
    rec_yard_per_pass_play = "Rec Yards/ Pass",
    rec_share = "Rec Share",
    total_yards_per_team_play = "Yards/ Team Play",
    cluster_examples = "Example Players") %>%
  cols_align(align = "center",
             columns = cols2) %>%
  fmt_number(
    columns = vars(ppr_ppg_total, rec_ypg_total, rush_ypg_total, draft_pick),
    decimals  = 1) %>%
  fmt_number(
    columns = vars(ep_diff_per_game_total, yc_per_attempt, mtf_per_attempt, rec_yard_per_pass_play, total_yards_per_team_play),
    decimals  = 2) %>%  
  fmt_percent(
    columns = vars(rec_share),
    decimals = 1) %>%
  tab_style(style = cell_text(size = "small"),
            locations = cells_body(columns = vars(cluster_examples))) %>%
  tab_spanner(
    label = "Outcome Metrics",
    columns = vars(ppr_ppg_total, rec_ypg_total, rush_ypg_total, ep_diff_per_game_total))%>%
  tab_spanner(
    label = "PCA Metrics",
    columns = vars(draft_pick, yc_per_attempt, mtf_per_attempt, rec_yard_per_pass_play, rec_share, total_yards_per_team_play)) %>%
  cols_width(vars(cluster_examples) ~ pct(15)) %>%
  tab_options(table.width = pct(100),
               data_row.padding = px(1))
  
```


<!-- # ```{r, echo = FALSE, message = FALSE, warning = FALSE} -->
<!-- # rb_clusters_wide %>% -->
<!-- #   select(name, Cluster, draft_pick, yc_per_attempt, mtf_per_attempt, rec_yard_per_pass_play, rec_share, total_yards_per_team_play) %>% -->
<!-- #   pivot_longer(cols = where(is.numeric), names_to = "Metric") %>% -->
<!-- #   mutate(Metric = factor(Metric, levels = c('draft_pick', 'yc_per_attempt', 'mtf_per_attempt', 'rec_yard_per_pass_play', -->
<!-- #                                             "rec_share", "total_yards_per_team_play"))) %>% -->
<!-- #   ggplot(aes(value, Cluster, fill = 100*stat(ecdf))) +  -->
<!-- #   stat_density_ridges(geom = "density_ridges_gradient", -->
<!-- #                       calc_ecdf = TRUE, -->
<!-- #                       quantiles = 4, -->
<!-- #                       quantile_lines = TRUE, -->
<!-- #                       jittered_points = TRUE, -->
<!-- #                       position = "points_sina", -->
<!-- #                       alpha = 0.8, -->
<!-- #                       point_color = "black" -->
<!-- #   ) +  -->
<!-- #   labs(title = "Distribution of Predictive Variables by Tier", -->
<!-- #        y = NULL, -->
<!-- #        fill = "Percentile") + -->
<!-- #   facet_wrap(~Metric, -->
<!-- #              scales = "free_x", -->
<!-- #              nrow = 3, -->
<!-- #              labeller = as_labeller(c('draft_pick' = 'Overall Draft Pick', -->
<!-- #                                       'yc_per_attempt' = 'Yards Created per attempt', -->
<!-- #                                       'mtf_per_attempt' = 'Missed Tackles Forced per attempt', -->
<!-- #                                       'rec_yard_per_pass_play' = 'Receiving Yards per pass play', -->
<!-- #                                       'rec_share' = 'Reception Share', -->
<!-- #                                       'total_yards_per_team_play' = 'Total Yards per team play'))) -->
<!-- # ``` -->

## Results

Now the fun part: let's see how these clusters performed in the NFL based on several outcome varibles. The data points represent one season, so a players in the 2016 draft class will have 4 points compared to one point for the class of 2019. While this biases the distributions towards the players with more data I believe it provides a better view on the types of seasons we can expect from each tier. Fantasy points over expectation is based on my own expected points model that will be up on the site before the start of the season.

* In a comparison of our early draft pick tiers, PC2 and PC5, the strong college reception share of PC5 translates better to NFL receiving production. This can be seen with a higher range of outcomes in receiving ypg as well as a higher floor for PPR ppg. PC2 is still my choice for the second strongest of the 6 tiers and actually boasts the best outcomes for outperforming their expected points.
* For the reasons outlined above, PC1 and PC3 have seen the worst NFL outcomes over the past 4 seasons. OVer 75% of the seasons from these players have produced fewer than 10 PPR ppg. Furthermore, they consistently produce fewer fantasy points than we would expect given their opportunity. While this may be caused by the fact that these are lower draft picks than the other tiers, it is also a red flag for any higher drafted player that may fall in these tiers.
* Our final two tiers, PC2 and PC6, show such similar outcomes that I cannot say with any confidence that one is preferable to the other. Slightly stronger outcomes in PPR ppg, fantasy points over expectation, and games played favors PC4, however more data is required to draw any conclusions. Both tiers clearly beat out PC1 and PC3 in most metrics.


```{r, echo = FALSE, message = FALSE, warning = FALSE}
rb_seasons_clusters %>%
  filter(Metric %in% c('ppr_ppg', 'rec_ypg', 'ep_diff_per_game', 'games')) %>%
  mutate(Metric = factor(Metric, levels = c('ppr_ppg', 'rec_ypg', 'ep_diff_per_game', 'games'))) %>%
  ggplot(aes(value, Cluster, fill = 100*stat(ecdf))) + 
    stat_density_ridges(geom = "density_ridges_gradient",
                        calc_ecdf = TRUE,
                        quantiles = 4,
                        quantile_lines = TRUE,
                        jittered_points = TRUE,
                        position = "points_sina",
                        alpha = 0.8,
                        point_color = "black"
                        ) + 
  labs(title = "Distribution of Outcome Variables by Tier",
       y = NULL,
       fill = "Percentile") +
  facet_wrap(~Metric,
             scales = "free_x",
             labeller = as_labeller(c('ppr_ppg' = 'PPR Points Per Game',
                                      'rec_ypg' = 'Receiving Yards Per Game',
                                      'ep_diff_per_game' = 'Fantasy Points Over Expected Per Game',
                                      'games' = 'Games Played')))
```



